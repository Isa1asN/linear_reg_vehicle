{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data reader from csv file\n",
    "def load_data(path, dataType, skip_header):\n",
    "    data = np.genfromtxt(path, delimiter=',', skip_header=skip_header, dtype=dataType)\n",
    "    return data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data columns of the data file \n",
    "dataType = [\n",
    "    ('name', 'U40'),\n",
    "    ('year', int),\n",
    "    ('selling_price', int),\n",
    "    ('km_driven', int),\n",
    "    ('fuel', 'U15'),\n",
    "    ('seller_type', 'U16'),\n",
    "    ('transmission', 'U15'),\n",
    "    ('owner', 'U20')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data \n",
    "data = load_data('car_data.csv', dataType, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4340\n",
      "4340\n",
      "4340\n",
      "4340\n",
      "4340\n",
      "4340\n",
      "4340\n",
      "4340\n"
     ]
    }
   ],
   "source": [
    "print(len(data['name'])) #the name is not that valuable tho\n",
    "print(len(data['year']))\n",
    "print(len(data['selling_price']))\n",
    "print(len(data['km_driven']))\n",
    "print(len(data['fuel']))\n",
    "print(len(data['seller_type']))\n",
    "print(len(data['transmission']))\n",
    "print(len(data['owner']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the categorical features should be encoded to make use of them\n",
    "seller_type_categories = [\"Individual\", \"Dealer\", \"Trustmark Dealer\"]\n",
    "fuel_categories = [\"Petrol\", \"Diesel\", \"CNG\", \"Electric\", \"LPG\"]\n",
    "transmission_categories = [\"Manual\", \"Automatic\"]\n",
    "owner_categories = [\"First Owner\", \"Second Owner\", \"Third Owner\", \"Fourth & Above Owner\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I used a integers to label the different categories\n",
    "seller_type_mapping = {\n",
    "    \"Individual\" : 1,\n",
    "    \"Dealer\" : 2,\n",
    "    \"Trustmark Dealer\" : 3\n",
    "}\n",
    "\n",
    "fuel_mapping = {\n",
    "    \"Petrol\" : 1,\n",
    "    \"Diesel\" : 2,\n",
    "    \"CNG\" : 3,  # CNG means Compressed Natural Gas\n",
    "    \"Electric\" : 4, \n",
    "    \"LPG\" : 5   # LPG means Liquefied Petroleum Gas\n",
    "}\n",
    "transmission_mapping = {\n",
    "    \"Manual\" : 1,\n",
    "    \"Automatic\" : 2\n",
    "}\n",
    "owner_mapping = {\n",
    "    \"First Owner\" : 1,\n",
    "    \"Second Owner\" : 2,\n",
    "    \"Third Owner\" : 3,\n",
    "    \"Fourth & Above Owner\" : 4,\n",
    "    \"Test Drive Car\" : 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These 6 are the ones to be used as a feature\n",
    "seller_type = np.array([seller_type_mapping[s_type] for s_type in data['seller_type']])\n",
    "fuel = np.array([fuel_mapping[f_type] for f_type in data['fuel']])\n",
    "transmission = np.array([transmission_mapping[t_type] for t_type in data['transmission']])\n",
    "owner = np.array([owner_mapping[o_type] for o_type in data['owner']])\n",
    "age = np.array([(2023-year) for year in data['year']])\n",
    "km_driven = np.array(data['km_driven'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing the X, the features matrix\n",
    "x_train = np.column_stack((seller_type, fuel, transmission, owner, age, km_driven))\n",
    "Y = np.array(data['selling_price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(X, y, w, b): \n",
    "    \"\"\"\n",
    "    compute cost\n",
    "    Args:\n",
    "      X (ndarray (m,n)): Data, m examples with n features\n",
    "      y (ndarray (m,)) : target values\n",
    "      w (ndarray (n,)) : model parameters  \n",
    "      b (scalar)       : model parameter\n",
    "      \n",
    "    Returns:\n",
    "      cost (scalar): cost\n",
    "    \"\"\"\n",
    "    m,n = X.shape\n",
    "    # calculate f_wb for all examples.\n",
    "    f_wb = X @ w + b  \n",
    "    # calculate cost\n",
    "    total_cost = (1/(2*m)) * np.sum((f_wb-y)**2)\n",
    "\n",
    "    # if verbose: print(\"f_wb:\")\n",
    "    # if verbose: print(f_wb)\n",
    "        \n",
    "    return total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116575.02131336405\n"
     ]
    }
   ],
   "source": [
    "print(compute_cost(x_train, Y, [1, 2, 3, 4, 5, 6], 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to compute the gradients\n",
    "def compute_gradient_matrix(X, y, w, b): \n",
    "    \n",
    "    m,n = X.shape\n",
    "    f_wb = X @ w + b              \n",
    "    e   = f_wb - y                \n",
    "    dj_dw  = (1/m) * (X.T @ e)    \n",
    "    dj_db  = (1/m) * np.sum(e)    \n",
    "    print(f\"the gradient {(dj_db,dj_dw)}\")\n",
    "    return dj_db,dj_dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, w_in, b_in, cost_function, gradient_function, alpha, num_iters): \n",
    "    \"\"\"\n",
    "    Performs batch gradient descent to learn theta. Updates theta by taking \n",
    "    num_iters gradient steps with learning rate alpha\n",
    "    \n",
    "    Args:\n",
    "      X : (array_like Shape (m,n)    matrix of examples \n",
    "      y : (array_like Shape (m,))    target value of each example\n",
    "      w_in : (array_like Shape (n,)) Initial values of parameters of the model\n",
    "      b_in : (scalar)                Initial value of parameter of the model\n",
    "      cost_function: function to compute cost\n",
    "      gradient_function: function to compute the gradient\n",
    "      alpha : (float) Learning rate\n",
    "      num_iters : (int) number of iterations to run gradient descent\n",
    "    Returns\n",
    "      w : (array_like Shape (n,)) Updated values of parameters of the model after\n",
    "          running gradient descent\n",
    "      b : (scalar)                Updated value of parameter of the model after\n",
    "          running gradient descent\n",
    "    \"\"\"\n",
    "    \n",
    "    # number of training examples\n",
    "    m = len(X)\n",
    "    \n",
    "    # An array to store values at each iteration primarily for graphing later\n",
    "    hist={}\n",
    "    hist[\"cost\"] = []; hist[\"params\"] = []; hist[\"grads\"]=[]; hist[\"iter\"]=[];\n",
    "    \n",
    "    w = copy.deepcopy(w_in)  #avoid modifying global w within function\n",
    "    b = b_in\n",
    "    save_interval = np.ceil(num_iters/10000) # prevent resource exhaustion for long runs\n",
    "\n",
    "    for i in range(num_iters):\n",
    "\n",
    "        # Calculate the gradient and update the parameters\n",
    "        dj_db,dj_dw = gradient_function(X, y, w, b)   \n",
    "\n",
    "        # Update Parameters using w, b, alpha and gradient\n",
    "        w = w - alpha * dj_dw               \n",
    "        b = b - alpha * dj_db               \n",
    "      \n",
    "        # Save cost J,w,b at each save interval for graphing\n",
    "        if i == 0 or i % save_interval == 0:     \n",
    "            hist[\"cost\"].append(cost_function(X, y, w, b))\n",
    "            hist[\"params\"].append([w,b])\n",
    "            hist[\"grads\"].append([dj_dw,dj_db])\n",
    "            hist[\"iter\"].append(i)\n",
    "\n",
    "        # Print cost every at intervals 10 times or as many iterations if < 10\n",
    "        if i% math.ceil(num_iters/10) == 0:\n",
    "            #print(f\"Iteration {i:4d}: Cost {cost_function(X, y, w, b):8.2f}   \")\n",
    "            cst = cost_function(X, y, w, b)\n",
    "            print(f\"Iteration {i:9d}, Cost: {cst:0.5e}\")\n",
    "    return w, b, hist #return w,b and history for graphing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 6 is different from 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[83], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m alpha \u001b[39m=\u001b[39m \u001b[39m5.0e-7\u001b[39m\n\u001b[0;32m      7\u001b[0m \u001b[39m# run gradient descent \u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m w_final, b_final, J_hist \u001b[39m=\u001b[39m gradient_descent(X, Y, initial_w, initial_b,\n\u001b[0;32m      9\u001b[0m                                                     compute_cost_matrix, compute_gradient_matrix, \n\u001b[0;32m     10\u001b[0m                                                     alpha, iterations)\n\u001b[0;32m     11\u001b[0m \u001b[39m# print(f\"b,w found by gradient descent: {b_final:0.2f},{w_final} \")\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[78], line 36\u001b[0m, in \u001b[0;36mgradient_descent\u001b[1;34m(X, y, w_in, b_in, cost_function, gradient_function, alpha, num_iters)\u001b[0m\n\u001b[0;32m     31\u001b[0m save_interval \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mceil(num_iters\u001b[39m/\u001b[39m\u001b[39m10000\u001b[39m) \u001b[39m# prevent resource exhaustion for long runs\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_iters):\n\u001b[0;32m     34\u001b[0m \n\u001b[0;32m     35\u001b[0m     \u001b[39m# Calculate the gradient and update the parameters\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m     dj_db,dj_dw \u001b[39m=\u001b[39m gradient_function(X, y, w, b)   \n\u001b[0;32m     38\u001b[0m     \u001b[39m# Update Parameters using w, b, alpha and gradient\u001b[39;00m\n\u001b[0;32m     39\u001b[0m     w \u001b[39m=\u001b[39m w \u001b[39m-\u001b[39m alpha \u001b[39m*\u001b[39m dj_dw               \n",
      "Cell \u001b[1;32mIn[77], line 5\u001b[0m, in \u001b[0;36mcompute_gradient_matrix\u001b[1;34m(X, y, w, b)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute_gradient_matrix\u001b[39m(X, y, w, b): \n\u001b[0;32m      4\u001b[0m     m,n \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape\n\u001b[1;32m----> 5\u001b[0m     f_wb \u001b[39m=\u001b[39m X \u001b[39m@\u001b[39;49m w \u001b[39m+\u001b[39m b              \n\u001b[0;32m      6\u001b[0m     e   \u001b[39m=\u001b[39m f_wb \u001b[39m-\u001b[39m y                \n\u001b[0;32m      7\u001b[0m     dj_dw  \u001b[39m=\u001b[39m (\u001b[39m1\u001b[39m\u001b[39m/\u001b[39mm) \u001b[39m*\u001b[39m (X\u001b[39m.\u001b[39mT \u001b[39m@\u001b[39m e)    \n",
      "\u001b[1;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 6 is different from 7)"
     ]
    }
   ],
   "source": [
    "# initialize parameters\n",
    "initial_w = np.zeros(6)\n",
    "initial_b = 0.\n",
    "# some gradient descent settings\n",
    "iterations = 1000\n",
    "alpha = 5.0e-7\n",
    "# run gradient descent \n",
    "w_final, b_final, J_hist = gradient_descent(X, Y, initial_w, initial_b,\n",
    "                                                    compute_cost_matrix, compute_gradient_matrix, \n",
    "                                                    alpha, iterations)\n",
    "# print(f\"b,w found by gradient descent: {b_final:0.2f},{w_final} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
